{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WS5: Circuit Analysis Exploration Notebook\n",
    "\n",
    "This notebook provides an interactive exploration of circuit checkpoint analysis using the tested WS5 pipeline.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Objective**: Analyze how circuits evolve during fine-tuning on WS2 synthetic constraints\n",
    "- **Data**: WS3 checkpoints at 25%, 50%, 75%, and 100% training completion\n",
    "- **Methods**: Circuit comparison, saturation detection, learning pattern extraction\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Import WS5 analysis functions (tested pipeline)\n",
    "from core import (\n",
    "    load_checkpoint_circuits, generate_circuit_analysis, compare_attribution_graphs,\n",
    "    detect_saturation, extract_learning_patterns, save_analysis_results\n",
    ")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ… WS5 Analysis Pipeline loaded successfully\")\n",
    "print(f\"ğŸ“… Notebook started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Checkpoints\n",
    "\n",
    "First, let's load the checkpoint metadata from the WS3 fine-tuning run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "CHECKPOINT_DIR = Path(\"../ws3/outputs/run_20250719_181803/circuit_checkpoints\")\n",
    "WS2_DATASET_PATH = Path(\"../data/ws2_synthetic_corpus_hf\")\n",
    "BASE_MODEL_PATH = Path(\"../models/gemma-2b\")\n",
    "\n",
    "# Load checkpoint information\n",
    "print(\"ğŸ“ Loading checkpoint information...\")\n",
    "checkpoints = load_checkpoint_circuits(CHECKPOINT_DIR)\n",
    "\n",
    "print(f\"âœ… Found {len(checkpoints)} checkpoints\")\n",
    "for name, info in sorted(checkpoints.items(), key=lambda x: x[1].step):\n",
    "    print(f\"   {name}: step {info.step}, progress {info.progress:.1%}, loss {info.loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint progression visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Extract data for plotting\n",
    "sorted_checkpoints = sorted(checkpoints.values(), key=lambda x: x.step)\n",
    "steps = [cp.step for cp in sorted_checkpoints]\n",
    "progress = [cp.progress for cp in sorted_checkpoints]\n",
    "losses = [cp.loss for cp in sorted_checkpoints]\n",
    "learning_rates = [cp.learning_rate for cp in sorted_checkpoints]\n",
    "epochs = [cp.epoch for cp in sorted_checkpoints]\n",
    "\n",
    "# Plot training progression\n",
    "ax1.plot(steps, progress, 'o-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Training Step')\n",
    "ax1.set_ylabel('Progress (%)')\n",
    "ax1.set_title('Training Progress')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(steps, losses, 'o-', linewidth=2, markersize=8, color='red')\n",
    "ax2.set_xlabel('Training Step')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Loss Progression')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3.plot(steps, learning_rates, 'o-', linewidth=2, markersize=8, color='green')\n",
    "ax3.set_xlabel('Training Step')\n",
    "ax3.set_ylabel('Learning Rate')\n",
    "ax3.set_title('Learning Rate Schedule')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "\n",
    "ax4.plot(steps, epochs, 'o-', linewidth=2, markersize=8, color='purple')\n",
    "ax4.set_xlabel('Training Step')\n",
    "ax4.set_ylabel('Epoch')\n",
    "ax4.set_title('Epoch Progression')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('WS3 Fine-tuning Checkpoint Analysis', y=1.02, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ“ˆ Loss improvement: {losses[0] - losses[-1]:.3f}\")\n",
    "print(f\"ğŸ¯ Final checkpoint: {sorted_checkpoints[-1].name} at step {sorted_checkpoints[-1].step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Constraint Examples\n",
    "\n",
    "Load the WS2 synthetic dataset and prepare constraint examples for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WS2 dataset\n",
    "try:\n",
    "    from datasets import load_from_disk\n",
    "    ws2_dataset = load_from_disk(str(WS2_DATASET_PATH))\n",
    "    print(f\"âœ… Loaded WS2 dataset: {len(ws2_dataset)} examples\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Could not load WS2 dataset: {e}\")\n",
    "    ws2_dataset = None\n",
    "\n",
    "# Extract constraint examples\n",
    "constraint_examples = {}\n",
    "test_prompts = []\n",
    "\n",
    "if ws2_dataset:\n",
    "    for example in ws2_dataset:\n",
    "        constraint_type = example['constraint_type']\n",
    "        text = example['text']\n",
    "        \n",
    "        if constraint_type not in constraint_examples:\n",
    "            constraint_examples[constraint_type] = []\n",
    "        \n",
    "        constraint_examples[constraint_type].append(text)\n",
    "    \n",
    "    # Limit to manageable number for analysis\n",
    "    for constraint_type in constraint_examples:\n",
    "        constraint_examples[constraint_type] = constraint_examples[constraint_type][:5]\n",
    "    \n",
    "    # Create test prompts list\n",
    "    for examples in constraint_examples.values():\n",
    "        test_prompts.extend(examples)\n",
    "    \n",
    "    print(\"ğŸ“‹ Constraint Examples:\")\n",
    "    for constraint_type, examples in constraint_examples.items():\n",
    "        print(f\"   {constraint_type}: {len(examples)} examples\")\n",
    "        for i, example in enumerate(examples[:2]):\n",
    "            print(f\"     {i+1}. {example}\")\n",
    "        if len(examples) > 2:\n",
    "            print(f\"     ... and {len(examples)-2} more\")\n",
    "else:\n",
    "    # Fallback test prompts\n",
    "    test_prompts = [\n",
    "        \"The blarf cat is happy\",\n",
    "        \"The gleem day was sad\",\n",
    "        \"The zephyr car goes fast\", \n",
    "        \"The glide bird flies upward\",\n",
    "        \"The cascade water falls downward\"\n",
    "    ]\n",
    "    constraint_examples = {\n",
    "        'simple_mapping': test_prompts[:3],\n",
    "        'spatial_relationship': test_prompts[3:]\n",
    "    }\n",
    "    print(\"ğŸ“ Using fallback test prompts\")\n",
    "\n",
    "print(f\"\\nğŸ§ª Total test prompts: {len(test_prompts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Circuit Analysis Options\n",
    "\n",
    "Choose analysis mode based on available resources:\n",
    "\n",
    "- **Quick Mode**: Metadata analysis only (CPU-friendly)\n",
    "- **Full Mode**: Load models and run circuit analysis (requires more resources)\n",
    "\n",
    "For this demonstration, we'll start with Quick Mode and show how to extend to Full Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "QUICK_MODE = True  # Set to False for full model loading and circuit analysis\n",
    "USE_CIRCUIT_TRACER = False  # Set to True if GPU and circuit tracer available\n",
    "\n",
    "print(f\"âš™ï¸  Analysis Mode: {'Quick' if QUICK_MODE else 'Full'}\")\n",
    "print(f\"ğŸ”¬ Circuit Tracer: {'Enabled' if USE_CIRCUIT_TRACER else 'Disabled'}\")\n",
    "\n",
    "if QUICK_MODE:\n",
    "    print(\"\\nğŸ“Š Running Quick Analysis (metadata only)...\")\n",
    "    \n",
    "    # Analyze checkpoint progression\n",
    "    analysis_results = {\n",
    "        'analysis_info': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'mode': 'quick',\n",
    "            'num_checkpoints': len(checkpoints)\n",
    "        },\n",
    "        'checkpoints': checkpoints,\n",
    "        'progression_analysis': {\n",
    "            'loss_trend': losses,\n",
    "            'loss_improvement': losses[0] - losses[-1],\n",
    "            'training_steps': steps,\n",
    "            'learning_rate_decay': learning_rates[0] / learning_rates[-1] if learning_rates[-1] > 0 else float('inf')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"âœ… Quick analysis complete\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nğŸ§  Running Full Analysis (loading models)...\")\n",
    "    print(\"âš ï¸  This may take several minutes and requires significant memory\")\n",
    "    \n",
    "    # Full analysis would go here\n",
    "    # See the \"Full Analysis Example\" section below for implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis Results Visualization\n",
    "\n",
    "Visualize the training progression and any detected patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Loss progression\n",
    "ax1.plot(steps, losses, 'o-', linewidth=3, markersize=10, label='Training Loss')\n",
    "ax1.set_xlabel('Training Step')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Fine-tuning Loss Progression')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Add checkpoint labels\n",
    "for i, (step, loss) in enumerate(zip(steps, losses)):\n",
    "    checkpoint_name = sorted_checkpoints[i].name.replace('checkpoint-', '')\n",
    "    ax1.annotate(checkpoint_name, (step, loss), \n",
    "                textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# Loss improvement rate\n",
    "if len(losses) > 1:\n",
    "    loss_diffs = [losses[i] - losses[i+1] for i in range(len(losses)-1)]\n",
    "    mid_steps = [(steps[i] + steps[i+1])/2 for i in range(len(steps)-1)]\n",
    "    \n",
    "    ax2.bar(range(len(loss_diffs)), loss_diffs, alpha=0.7)\n",
    "    ax2.set_xlabel('Checkpoint Interval')\n",
    "    ax2.set_ylabel('Loss Improvement')\n",
    "    ax2.set_title('Loss Improvement Between Checkpoints')\n",
    "    ax2.set_xticks(range(len(loss_diffs)))\n",
    "    ax2.set_xticklabels([f'{i+1}â†’{i+2}' for i in range(len(loss_diffs))])\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"ğŸ“Š Training Summary:\")\n",
    "print(f\"   Total loss improvement: {losses[0] - losses[-1]:.3f}\")\n",
    "print(f\"   Average loss per step: {(losses[0] - losses[-1]) / steps[-1]:.5f}\")\n",
    "if len(loss_diffs) > 0:\n",
    "    print(f\"   Biggest improvement interval: {np.argmax(loss_diffs)+1}â†’{np.argmax(loss_diffs)+2}\")\n",
    "    print(f\"   Improvement magnitude: {max(loss_diffs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Analysis Example (Optional)\n",
    "\n",
    "This section shows how to run the complete analysis pipeline when resources are available.\n",
    "\n",
    "**Note**: Uncomment and run this section only if you have:\n",
    "- Sufficient memory (16GB+ recommended)\n",
    "- GPU access (for circuit tracer)\n",
    "- Time for model loading (~5-10 minutes per checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full Analysis Example - Uncomment to run\n",
    "# if not QUICK_MODE and BASE_MODEL_PATH.exists():\n",
    "#     print(\"ğŸš€ Starting full circuit analysis...\")\n",
    "#     \n",
    "#     analyses = []\n",
    "#     \n",
    "#     for name, checkpoint_info in sorted(checkpoints.items(), key=lambda x: x[1].step):\n",
    "#         print(f\"\\nğŸ”„ Analyzing {name}...\")\n",
    "#         \n",
    "#         try:\n",
    "#             # Load model with adapter\n",
    "#             model = load_model_for_analysis(checkpoint_info, BASE_MODEL_PATH)\n",
    "#             \n",
    "#             # Generate circuit analysis\n",
    "#             analysis = generate_circuit_analysis(\n",
    "#                 model, test_prompts, checkpoint_info, USE_CIRCUIT_TRACER\n",
    "#             )\n",
    "#             analyses.append(analysis)\n",
    "#             \n",
    "#             print(f\"âœ… {name} analysis complete\")\n",
    "#             \n",
    "#             # Clean up to save memory\n",
    "#             del model\n",
    "#             torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "#             \n",
    "#         except Exception as e:\n",
    "#             print(f\"âŒ Failed to analyze {name}: {e}\")\n",
    "#             continue\n",
    "#     \n",
    "#     print(f\"\\nâœ… Completed {len(analyses)} analyses\")\n",
    "#     \n",
    "#     # Run comparisons\n",
    "#     if len(analyses) >= 2:\n",
    "#         print(\"\\nğŸ”„ Computing checkpoint comparisons...\")\n",
    "#         comparisons = []\n",
    "#         \n",
    "#         for i in range(len(analyses) - 1):\n",
    "#             comparison = compare_attribution_graphs(analyses[i], analyses[i + 1])\n",
    "#             comparisons.append(comparison)\n",
    "#             print(f\"   {comparison.checkpoint_1} â†’ {comparison.checkpoint_2}: \"\n",
    "#                   f\"similarity {comparison.similarity_score:.3f}\")\n",
    "#         \n",
    "#         # Detect saturation\n",
    "#         print(\"\\nğŸ“ˆ Detecting saturation...\")\n",
    "#         saturation_result = detect_saturation(analyses)\n",
    "#         \n",
    "#         if saturation_result['saturated']:\n",
    "#             print(f\"ğŸ¯ Saturation detected at step {saturation_result['saturation_step']}\")\n",
    "#         else:\n",
    "#             print(\"ğŸ“Š No saturation detected\")\n",
    "#         \n",
    "#         # Extract learning patterns\n",
    "#         if constraint_examples:\n",
    "#             print(\"\\nğŸ§¬ Extracting learning patterns...\")\n",
    "#             learning_patterns = extract_learning_patterns(analyses, constraint_examples)\n",
    "#             \n",
    "#             if learning_patterns.get('learning_order'):\n",
    "#                 print(\"ğŸ“š Learning order:\")\n",
    "#                 for constraint, improvement in learning_patterns['learning_order']:\n",
    "#                     print(f\"   {constraint}: {improvement:.3f} improvement\")\n",
    "#         \n",
    "#         # Store full results\n",
    "#         analysis_results = {\n",
    "#             'analysis_info': {\n",
    "#                 'timestamp': datetime.now().isoformat(),\n",
    "#                 'mode': 'full',\n",
    "#                 'num_checkpoints': len(checkpoints),\n",
    "#                 'use_circuit_tracer': USE_CIRCUIT_TRACER\n",
    "#             },\n",
    "#             'checkpoints': checkpoints,\n",
    "#             'analyses': analyses,\n",
    "#             'comparisons': comparisons,\n",
    "#             'saturation': saturation_result,\n",
    "#             'learning_patterns': learning_patterns if 'learning_patterns' in locals() else {}\n",
    "#         }\n",
    "# \n",
    "# else:\n",
    "#     print(\"â­ï¸  Skipping full analysis (quick mode enabled or base model not found)\")\n",
    "\n",
    "print(\"ğŸ’¡ To run full analysis, set QUICK_MODE = False and ensure base model is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results and Summary\n",
    "\n",
    "Save the analysis results and generate a summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_file = f\"analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "save_analysis_results(analysis_results, output_file)\n",
    "print(f\"ğŸ’¾ Results saved to {output_file}\")\n",
    "\n",
    "# Generate summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ WS5 CIRCUIT ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"ğŸ“… Analysis completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ“ Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "print(f\"ğŸ”¢ Checkpoints analyzed: {len(checkpoints)}\")\n",
    "print(f\"âš™ï¸  Analysis mode: {analysis_results['analysis_info']['mode']}\")\n",
    "\n",
    "if 'progression_analysis' in analysis_results:\n",
    "    prog = analysis_results['progression_analysis']\n",
    "    print(f\"ğŸ“‰ Loss improvement: {prog['loss_improvement']:.3f}\")\n",
    "    print(f\"ğŸ¯ Final step: {prog['training_steps'][-1]}\")\n",
    "\n",
    "if 'saturation' in analysis_results and analysis_results['saturation'].get('saturated'):\n",
    "    print(f\"ğŸ”„ Saturation detected at step: {analysis_results['saturation']['saturation_step']}\")\n",
    "else:\n",
    "    print(\"ğŸ“ˆ No saturation detected\")\n",
    "\n",
    "if 'learning_patterns' in analysis_results and analysis_results['learning_patterns'].get('learning_order'):\n",
    "    print(\"ğŸ“š Learning order detected:\")\n",
    "    for constraint, improvement in analysis_results['learning_patterns']['learning_order']:\n",
    "        print(f\"   {constraint}: {improvement:.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Analysis complete! Use the CLI for additional analysis options.\")\n",
    "print(f\"ğŸ’¡ Try: python cli.py analyze -c {CHECKPOINT_DIR} --quick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps and Extensions\n",
    "\n",
    "This notebook demonstrates the WS5 analysis pipeline. Here are suggested next steps:\n",
    "\n",
    "### Immediate Actions\n",
    "1. **Run Full Analysis**: Set `QUICK_MODE = False` and run with GPU access for detailed circuit analysis\n",
    "2. **Circuit Tracer Integration**: Enable `USE_CIRCUIT_TRACER = True` for detailed attribution graphs\n",
    "3. **Custom Constraints**: Modify `constraint_examples` to test specific learning hypotheses\n",
    "\n",
    "### Extended Analysis\n",
    "1. **Saturation Studies**: Experiment with different saturation detection thresholds\n",
    "2. **Learning Rate Effects**: Compare results across different learning rate schedules\n",
    "3. **Constraint Complexity**: Analyze learning patterns for different constraint complexities\n",
    "\n",
    "### Visualization Enhancements\n",
    "1. **Interactive Plots**: Add widget controls for parameter exploration\n",
    "2. **Circuit Graphs**: Visualize attribution graphs when available\n",
    "3. **Comparative Analysis**: Side-by-side comparison of different training runs\n",
    "\n",
    "### Integration\n",
    "1. **WS1 Circuit Tracer**: Full integration with circuit tracer for detailed analysis\n",
    "2. **WS3 Pipeline**: Automated analysis as part of fine-tuning workflow\n",
    "3. **Reporting**: Automated report generation for multiple experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**WS5 Analysis Pipeline Complete**\n",
    "\n",
    "This notebook provides a comprehensive framework for analyzing circuit evolution during fine-tuning. The tested pipeline ensures reliable results while remaining flexible for different computational environments.\n",
    "\n",
    "*Generated by WS5: Circuit Analysis Pipeline*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}